\chapter{Background}%
\label{chp:background}

\section{Related Works}%
\label{sec:related}

In the literature, there is no absence of works in the field of \gls{ml}-based
intrusion detection. This section, will briefly outline some significant works
in the field.

In 2020, Karatas et al.~\cite{Karatas} proposed 6 \gls{ml}-based \gls{ids},
employing the techniques of K Nearest Neighbours, Random Forest, Gradient
Boosting, Adaboost, Decision Tree and Linear Discriminant Analysis. They
evaluated their models on the CSE-CIC-IDS 2018 dataset. Due to the class
imbalance present in this dataset, the authors applied the \gls{smote}. The
results indicate the proposed models are very effective with accuracies on the
sampled data ranging from 91.18\% to 99.35\%. The Random Forest algorithm had
the highest accuracy on the sampled dataset, however the Adaboost algorithm had
the highest precision and F1 score which may be more significant given the
class imbalance present in the dataset.

Zuech et al.\ in 2021~\cite{Zuech}, investigate the efficacy of different
undersampling ratios in detecting web attacks. They consider eight different
ratios, specifically: no sampling, 999:1, 99:1, 95:5, 9:1,3:1, 65:35 and 1:1.
Seven different classifiers are employed in the study: Decision Tree, Random
Forest, CatBoost, LightGBM, XGBoost, Naive Bayes and Logistic Regression. The
study found that undersampling significantly improved the performance of these
\gls{ml} models and that LightGBM was the top performer. The conclusion of the
study was that the undersampling ratio, classifier, and interaction between the
two were all statistically significant to the efficacy of web intrusion
detection.

Jiang et al. (2020)~\cite{Jiang} take a \gls{dl} approach to the problem. They
propose a \gls{cnn} to extract spatial features, which are then processed
through a \gls{bilstm} network to extract temporal features. To handle class
imbalance, the authors first apply \gls{oss} to reduce noisy samples in the
majority class, then increase the number of minority samples through
\gls{smote}. The proposed solution is evaluated on both the NSL-KDD dataset and
the UNSW-NB15 dataset, achieving accuracies of 83.58\% and 77.16\%
respectively.

Khan (2021)~\cite{Khan} takes a similar approach proposing a hybrid
convolutional recurrent neural network-based \gls{ids}. The hybrid model,
similar to the work of Jiang et al.~\cite{Jiang}, extracts features using a
\gls{cnn}, then feeds the extracted features to a \gls{rnn} classifier. Class
imbalance is handled through oversampling, specifically by arbitrarily
replicating minority samples. The proposed model is evaluated on the
CSE-CIC-IDS2018 dataset, achieving an accuracy of up to 97.75\% when using
10-fold-cross-validation.

Mighan and Kahani (2021)~\cite{Mighan} propose a hybrid approach using a
stacked auto-encoder network for latent feature extraction followed by a
support vector machine classifier. The proposed model was evaluated on the
ISCX2012 and CICIDS2017 datasets achieving accuracies of 90.2\% and 99.49\%
respectively. They concluded that \gls{dl} feature extraction outperformed
other methods. Note, class imbalance was not addressed in this study, despite
being present in both datasets used.

Kus et al. (2022)~\cite{Kus} argue that the current evaluation standard in
\gls{ml}-based industrial intrusion detection may create a false sense of
security. They argue that it does not assess the model's ability to detect
unknown attacks, absent from the training set. They propose a new evaluation
methodology to assess the efficacy of \gls{ml}-based industrial \gls{ids} in
detecting these unknown attacks.

The methodology involves iteratively training and testing the model. The
procedure consists of 4 phases. In the first phase, one attack category is
excluded from the training set each iteration. Hence, the generalisability to
this unseen attack can be measured from the evaluation on the test set. In the
second phase, only one attack category is included in the training set,
allowing the relations between different attack categories to be investigated.
Finally, in the third and fourth phase, the first two phases are repeated
however using individual attacks in place of attack categories.

This methodology is applied to three industrial intrusion detection models
proposed in a work by Lopez Perez et al.~\cite{Perez} The results indicate an
alarmingly low ability to recognise unseen attacks, with detection rates
dropping to between 3.2\% and 14.7\% for some types of attacks. The authors
conclude that the models they tested only learn signatures of attacks and are
not performing true anomaly-based intrusion detection. The study focuses
primarily on industrial intrusion detection and does not attempt to make any
generalisations to other domains of intrusion detection.

A literature review carried out in 2023 by Ahmad et al.~\cite{zero-day} reviews
many more similar works with a particular focus on zero-day attacks. It
supports the argument of Kus et al.~\cite{Kus} stating that many researchers in
the field are not currently addressing the existence of zero-day attacks and
suggests that future works should not assume all existing attack
classifications are present in the dataset.

\section{Conclusion}%
\label{sec:conclusion}
From the above works, we observe that the research community has achieved
very impressive results in the field of intrusion detection. However, as Kus et
al.\ have discovered, these laboratory results may not accurately reflect
reality.

\gls{aids} is said to be able to detect zero-day attacks as it categorises
traffic based on its behaviour as opposed to particular
signatures~\cite{aids-zero-day}. However, current state of the art
\gls{ml}-based \gls{ids} are typically trained on labelled data, meaning the
resultant models are classification models as opposed to true anomaly detection
models. This may bring them closer to \gls{sids} than \gls{aids}, significantly
reducing their efficacy in detecting zero-day attacks.
