\chapter{Proposed Evaluation}%
\label{chp:evaluation}

The work of Kus et al.~\cite{Kus} and Zoppi et al.~\cite{Zoppi} shines an
illuminating light onto the field. Hence, this study follows similar
principles.

Models are evaluated using the methodology of Kus et al.~\cite{Kus} as this is
a superset of the methodology applied by Zoppi et al.~\cite{Zoppi}.
Additionally, Kus et al.~\cite{Kus} consider individual attacks, which will
provide valuable insights to address \hyperlink{obj3}{Objective 3}.

The methodology can be divided into the five following steps:
\begin{enumerate}
      \item Selection of state-of-the-art models.
      \item Selection of a realistic and diverse dataset.
      \item Sampling and preprocessing of the dataset.
      \item Generation of training variants which intentionally exclude certain attacks.
      \item Evaluation of the replicated models on the training variants.
\end{enumerate}
The remainder of this chapter will further detail these steps.

\section{Selection of Models}%
\label{sec:models}

The methodology is applied to several state-of-the-art models designed for
general purpose datasets belonging to three families. Namely, these families
are supervised traditional \gls{ml} techniques, unsupervised traditional
\gls{ml} techniques and unsupervised \gls{dl} techniques. It should be noted
that supervised \gls{dl} techniques are not considered as they have been found
to be less effective by Zoppi et al.~\cite{Zoppi}.

The study replicates the models proposed in the works of Karatas et
al.~\cite{Karatas} and Pu et al.~\cite{Pu} as well as the \gls{sae}-\gls{ocsvm}
proposed by Cao et al.~\cite{Cao}. These works have been selected as they are
the most highly cited amongst recent studies that provide clear methodologies
from the families we aim to compare.

In addition, the work of Karatas et al.~\cite{Karatas} addresses class
imbalance, which is a significant problem when applying supervised \gls{ml} to
intrusion detection. This is due to the prevalence of normal, non-malicious
traffic in realistic scenarios when compared to the volume of malicious
traffic~\cite{imbalance_prob, imbalance}.

The \gls{sae}-\gls{ocsvm} model was selected from those proposed by Cao et
al.~\cite{Cao} as it demonstrates the highest efficacy on the NSL-KDD dataset
and is also amongst the most effective models on all other datasets considered
by the authors.

\section{Datasets}%
\label{sec:datasets}
The CSE-CIC-IDS2018 dataset is a collaborative effort between the
Communications Security Establishment and the Canadian Institute of
Cybersecurity,
and serves as a successor to the CICIDS2017 dataset which is a smaller, less
diverse counterpart. The aim of the project was to produce an up to date,
realistic dataset for the evaluation of \gls{nids}. The dataset was generated
on infrastructure consisting of a victim network with 420 machines and 30
servers, and an attack network consisting of 50 machines. The machines were
divided into departments mimicking a typical corporate network. A typical
network environment was simulated using B-profiles, which describe user
behaviour through statistical and \gls{ml} techniques, allowing it to be
accurately replicated. The dataset includes a variety of modern attack
categories, namely, \gls{dos} attacks, brute force attacks, code injection,
botnet attacks, and infiltration attacks which involve using an exploit on a
host inside the network to attack the network. The resulting dataset contains
80 features and approximately 16,000,000 instances~\cite{cic2018, cic2018data}.

The CSE-CIC-IDS2018 dataset is, to the best of our knowledge, the most
up-to-date, general purpose network intrusion dataset publicly available today.
It offers a large volume of data containing diverse attack scenarios and a
realistic network environment. It is for these reasons that it has been used to
evaluate and compare the models of this study.

The NSL-KDD~\cite{nsl} dataset is an improvement over its predecessor, the
KDD99 dataset. It was created as a benchmark for intrusion detection systems
and offers a more balanced class distribution than its predecessor. The dataset
has been used extensively in the field of intrusion detection, however, the
underlying network data dates back to 1998. Both the unsupervised models this
study replicates have been evaluated on this dataset by the original authors.
Hence, this dataset is used to verify the models were replicated correctly, but
is not used to make comparisons as due to its age, the results may not
generalise well to the modern cyber threat landscapes.

\section{Preprocessing}%
\label{sec:preprocessing}

The methodology we employ requires each instance in the dataset to be labelled
with both the specific attack name and the attack category. The labels provided
in the CSE-CIC-IDS2018 dataset can be described as an attack category, however,
some labels are not broad enough to be defined as categories for the purpose of
this study. An instance of this are the \gls{dos} attacks which are labelled
according to the specific tool used. Hence, the dataset has an `attack name'
column appended to it. The values of this column were filled according to Table
2 on the dataset's website~\cite{cic2018}, using the `Timestamp' and `Label'
columns to determine the attack each instance belongs to.

Numerous instances in the dataset occur outside the specified attack times in
this table. In most cases, only one attack with a particular label occurred
each day. Hence, it has been assumed that instances with a matching label,
occurring outside the specified attack times, but on the same attack day
constitute part of that attack. The exception to this are the bot attacks
carried out on 02/03/2018. Two Bot attacks were carried out on the same day,
with malicious instances present between the end time of the first attack and
the start time of the second. These instances have been labelled as the
`Unknown' attack type.

Next, an `attack category' column was generated from this new column. The
categorisation adopted for this study is shown in Table~\ref{tab:categories}.
It should be noted that the previously mentioned ambiguous bot attacks were
categorised as `Bot' attacks.

\begin{table}
      \centering
      \caption{Attack Categorisation\label{tab:categories}}
      \begin{tblr}{|Q[m,0.2\textwidth]|Q[m,0.2\textwidth]|}
            \hline
            Category                     & Original Label           \\
            \hline
            Benign                       & Benign                   \\
            \hline
            \SetCell[r=4]{m} Brute Force & FTP-BruteForce           \\
                                         & FTP-BruteForce           \\
                                         & SSH-BruteForce           \\
                                         & Brute Force -Web         \\
            \hline
            \SetCell[r=7]{m} \gls{dos}   & DoS attacks-GoldenEye    \\
                                         & DoS attacks-Slowloris    \\
                                         & DoS attacks-SlowHTTPTest \\
                                         & DoS attacks-Hulk         \\
                                         & DDoS attacks-LOIC-HTTP   \\
                                         & DDOS attack-LOIC-UDP     \\
                                         & DDOS attack-HOIC         \\
            \hline
            Bot                          & Bot                      \\
            \hline
            Infiltration                 & Infilteration            \\
            \hline
            \SetCell[r=2]{m} Injection   & SQL Injection            \\
                                         & Brute Force -XSS         \\
            \hline
      \end{tblr}
\end{table}

As noted by Ahmad et al.~\cite{zero-day}, categorising attacks into broad
labels, such as \gls{dos}, can create inconsistencies and confusion in the
literature due to their subjectivity. Hence, the categorisations used in this
paper should be interpreted as a shorthand method of referring to the specific
attack types included under the category in this study. This shorthand serves
to simplify the process of investigating generalisation across attacks that
differ significantly in their nature and attacks that share similarities.
Conclusions are not be intended to generalise to attack types not present in
the dataset that may fall under the same subjective categorisation.

The CSE-CIC-IDS2018 dataset contains approximately 16,000,000 instances, an
enormous number that introduces complexities as it is not feasible to keep the
full dataset in memory during processing on the 32GB of RAM that were available
for this project. Hence, the dataset was sampled to 4,519,553 instances. The
sampling strategy adopted was random sampling of 28\% of the data.

Once the sampled, fully labelled dataset was generated, the individual
preprocessing pipelines of each replicated study were applied. Some additional
steps were added where necessary. We will now briefly outline the steps taken
in each work.

The following steps, based on the methodology of Karatas et al.~\cite{Karatas},
were carried out prior to all experiments.

\begin{enumerate}
      \item The CSE-CIC-IDS2018 dataset contains data points dated 1970 with illogical
            values in certain columns, likely caused by overflow errors during dataset
            generation. All instances of such data points were removed from the sample.
            Additionally, instances with an `Unknown' attack type were also removed.
      \item Missing values were replaced with zero
      \item Infinity values were replaced with the maximum value in the column
      \item During replication, the `Timestamp' columns was separated into date and time
            columns to eliminate non-numeric values. The column was then removed for the
            experiments as none of the models replicated analyse time series data. Hence,
            any information present in this column will be valid only under the specific
            conditions of the attacks present in the dataset, diminishing the realism of
            the experiments.
      \item The columns `Src IP', `Dst IP' and `Flow ID' similarly contain information
            specific to the attack configuration employed in the generation of the dataset.
            Hence, these have also been removed.
      \item Two columns contain negative values, `Init Fwd Win Byts' and `Init Bwd Win
            Byts'. Two additional categorical columns were added, containing a one for
            negative values and a zero for positive values in the corresponding column.
      \item The label column was encoded into numeric values. This was done for both the
            `attack category' and `attack name' columns for the purposes of this study.
      \item The dataset was shuffled.
      \item Lastly, \gls{smote} was employed to reduce the class imbalance present in the
            dataset. % TODO: give parametrs and sampling strategy
\end{enumerate}

The following additional steps were carried out following the steps mentioned
above, based on the methodology of Cao et al.~\cite{Cao}.
\begin{enumerate}
      \item The negative one values present in the columns `Init Fwd Win Byts' and `Init
            Bwd Win Byts' were replaced by -0.5 values. This is so that they scale back to
            their original negative one value following the log operation.
      \item All malicious samples were filtered out of the training set, and the training
            set was reduced to 6734 samples. This number was selected as it was the number
            used by the original authors, and our experimentation with different sample
            sizes failed to yield better results.
      \item Next, columns containing large values had one added to them followed by the
            logarithm operation base two.
      \item Finally, each feature was scaled by its maximum absolute value.
\end{enumerate}

\section{Training Variants}%
\label{sec:variants}

Following preprocessing, the dataset was split into variants according to the
methodology of Kus et al.~\cite{Kus}. Briefly, this consists of filtering the
dataset in four phases. In the first phase, the dataset has particular attack
excluded from the training set. Hence, the excluded attacks simulate unknown
attacks and accurately depict model performance on such unknown attacks should
it encounter them at runtime. In the second phase, all attacks are filtered out
except for one attack, and of course, the benign class. This provides more
insight allowing for a better understanding of how indiviudal attacks provide
valuable knowledge that may generalise to other attacks. In the thrid and
fourth phases, these two steps are repeated using attack categories instead of
particular attack types. This provides more insight as to how attacks may
generalise to other attacks within the same categories as well as attacks in
other categories.

The CSE-CIC-IDS2018 contains 21 individual attacks, which have been divided
into five categories. Hence, 52 dataset variants were generated.

\section{Implementation and Execution}%
\label{sec:implementation}

The evaluation of this study is written in Python 3.11. The models employed by
Karatas et al.~\cite{Karatas} were implemented using the scikit-learn
library~\cite{scikit-learn} as was done by the original authors. The work of Pu
et al.~\cite{Pu} was replicated using ThunderSVM~\cite{ThunderSVM}, a
GPU-accelerated library that offers an \gls{ocsvm} implementation. Cao et
al.~\cite{Cao} provide the source code of their implementation on
GitHub~\cite{cao_git}. This implementation employs Tensorflow~\cite{tensorflow}
for the \gls{sae} and sci-kit learn for the \gls{ocsvm} model. The \gls{sae}
implementation was updated to work with Tensorflow 2 and the \gls{ocsvm} model
was replaced with a ThunderSVM~\cite{ThunderSVM} model to reduce execution
time.

The results of each original study were replicated on one of the datasets used
by the original authors to verify the models were replicated correctly. Once,
matching results were achieved, the models were trained on the variants to
produce the results of this study. The unsupervised models considered expect
only normal, or benign, data in their training sets. Hence, these were only
trained once as all variants are rendered identical when malicious samples are
omitted. Each model was trained as a binary classification model, classifying
each sample as benign or malicious.

% In the ideal case, the evaluation metrics of 
% each dataset variant would be calculated using 5-fold cross validation.
% However, due to the high computational demands of the methodology, there is a
% possibility that the proposed procedure will be unfeasible to carry out using
% the resources available. Should this be the case, a standard train-test split
% may be employed in place of 5-fold cross validation and stratified sampling can
% be explored to reduce the size of the dataset without decreasing the quality of
% the results.

\section{Hyperparameters}%
\label{sec:hyperparameters}

Table~\ref{tab:hyperparameters} specifies the hyperparameters used for each
model in this study.

\begin{table}
      \caption{Aggregate results when excluding specific
            attacks\label{tab:hyperparameters}}
      \centering
      \begin{tblr}{|c|c|c|c|c|c|c|}
            \hline
            \textbf{Model}        & \textbf{Hyperparameters}                                                                                                  \\
            \hline
            \gls{dt}              & splitter=`best' criterion=`Gini' min_samples_split=2 min_samples_leaf=1                                                   \\
            \gls{rf}              & n_estimators=100 min_samples_split=2 min_samples_leaf=1 criterion=`Gini                                                   \\
            \gls{gb}              & loss=`log_loss' learning_rate=1 n_estimators=100 max_depth=3 validation_fraction=0.1                                      \\
            \gls{knn}             & n_neighbours=5 weights=`uniform' metric=`Minkowski'                                                                       \\
            \gls{lda}             & solver=`svd'                                                                                                              \\
            \gls{ssc}-\gls{ocsvm} &                                                                                                                           \\
            \gls{sae}-\gls{ocsvm} & lambda=10 learning_rate=0.01 n_neurons_layer_1=85 n_neurons_layer_2=49 n_neurons_layer_3=12 nu=0.5 kernel=`rbf' gamma=0.1 \\
            \hline
      \end{tblr}
\end{table}